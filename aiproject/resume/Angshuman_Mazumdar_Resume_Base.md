# ANGSHUMAN MAZUMDAR
**Data Engineer | Analytics Engineer | Business Intelligence**

angshuman_mazumdar@hotmail.com | +91 8197590010 | Bengaluru, India | Open to Remote (UTC+5:30)
linkedin.com/in/angshuman-mazumdar | github.com/[YOUR-GITHUB-USERNAME]

---

## PROFESSIONAL SUMMARY

Data Engineering professional with 8+ years of experience building data pipelines, BI systems,
and analytics platforms that directly impact business outcomes. Snowflake Certified Data Engineer
with hands-on expertise in cloud data warehousing (Snowflake), ETL/ELT pipeline development,
SQL, Python (Snowpark), and real-time dashboards. Proven leader who has driven 110%+ net
revenue retention and mentored analytics teams across high-growth startups. Brings a rare
combination of technical depth and business fluency — translating raw data into executive-level
insights. Actively building expertise in dbt, Airflow, and modern data stack tooling.

---

## TECHNICAL SKILLS

| Category | Tools & Technologies |
|---|---|
| **Cloud Data Warehouse** | Snowflake (SnowPro Advanced Certified), Dynamic Tables, Streams, Snowpark, Tasks, Alerts |
| **Data Engineering** | SQL, Python (pandas, requests), ETL/ELT Pipelines, Data Modeling, Star Schema |
| **BI & Visualization** | Looker Studio, Power BI, Zoho Analytics, Streamlit, Altair |
| **DevOps & CI/CD** | GitHub Actions, Snowflake CLI, Git, Version Control |
| **Data Governance** | Data Quality Frameworks, Data Validation, Compliance Monitoring, Audit Pipelines |
| **Analytics** | KPI Development, Trend Analysis, Root Cause Analysis, VOC Analysis, A/B Testing |
| **Soft Skills** | Cross-functional Leadership, Stakeholder Management, Team Mentoring, MBR/QBR |

---

## CERTIFICATIONS

**Cloud & Data Engineering**
- **Data Engineering Professional Certificate** | Snowflake | Feb 2026
- **Advanced Data Engineering with Snowflake** | LinkedIn Learning | Feb 2026
- **Introduction to Modern Data Engineering with Snowflake** | LinkedIn Learning | Feb 2026
- **Intro to Snowflake for Devs, Data Scientists & Data Engineers** | LinkedIn Learning | Feb 2026
- **Hands-On Introduction: Data Engineering** | LinkedIn Learning | Jan 2026
- **Data Engineering Foundations** | LinkedIn Learning | Jan 2026

**Analytics & Strategy**
- **Building KPIs for Data-Driven Strategy** | LinkedIn Learning | Jan 2026

**Other**
- **Network Technician** | Dimension Data (NTT Company)
- **EFSET English Proficiency** | CEFR B1/B2 | EF Standard English Test

---

## PROFESSIONAL EXPERIENCE

### Regional Manager — Analytics, CRM & Customer Success
**Pazcare** | Bengaluru, India | Jun 2023 – Feb 2026

- Achieved **110%+ Net Revenue Retention (NRR)** quarter-over-quarter by building data-driven
  customer success frameworks and real-time performance monitoring systems.
- Designed and maintained **ETL pipelines** integrating multiple data sources into BI platforms
  (Looker Studio, Zoho Analytics), enabling unified, real-time reporting for leadership.
- Wrote complex **SQL queries** to extract, transform, and analyze large datasets for strategic
  decision-making across customer success, operations, and product teams.
- Built **interactive dashboards, KPI scorecards, and MBR/QBR reporting packs** providing
  C-suite visibility into business health, retention metrics, and operational performance.
- Implemented **automated alerting and monitoring systems** to proactively flag data anomalies,
  churn risks, and SLA deviations before they impacted business outcomes.
- Led **data validation, cleansing, and governance initiatives** ensuring data accuracy,
  consistency, and compliance across CRM and analytics systems.
- Conducted **trend analysis and root-cause diagnostics** to identify levers for customer
  retention, engagement improvement, and cost reduction.
- Analyzed **Voice of Customer (VOC)** data to inform product enhancements and service
  delivery improvements in collaboration with Product and Tech teams.
- Mentored team members on **SQL, BI tools, data management practices**, and reporting
  methodologies, building internal analytics capability from the ground up.

---

### Lead — Data Management & Operational Governance
**Zeta Suite** | Mar 2022 – Jun 2023

- Led **data management and operational governance** across enterprise client accounts ensuring
  data accuracy, security, and regulatory compliance.
- Established **data quality frameworks and validation checks** ensuring consistency across
  client systems and reporting environments.
- Built **audit-ready dashboards and documentation** providing leadership visibility into
  compliance posture, billing accuracy, and SLA adherence.
- Managed **client audits and compliance reviews**, validating data integrity against
  contractual and statutory requirements.
- Directed **billing reconciliation workflows**, streamlining data pipelines for accurate,
  transparent enterprise invoicing.
- Implemented **incident reporting and escalation protocols**, improving response times and
  data accountability across business units.

---

### Business Analyst — Operations & Service Analytics
**NoBrokerHood** | Dec 2020 – Mar 2022 | Bengaluru

- Designed and tracked **service team KPIs** measuring productivity, turnaround time,
  first-time resolution, and CSAT across multiple service channels.
- Developed **data models and real-time performance dashboards** for agent productivity,
  ticket volumes, and SLA adherence monitoring.
- **Automated reporting and incentive calculation pipelines**, eliminating manual effort and
  ensuring accuracy in performance-linked payouts.
- Conducted **root-cause analysis** on recurring service bottlenecks, implementing data-driven
  improvements that measurably enhanced operational efficiency.
- Integrated data flows between **CRM, ticketing, and reporting systems** enabling end-to-end
  analytics visibility across the service function.
- Built **performance tracking frameworks** aligning individual and team incentives with
  business goals and customer experience outcomes.

---

### Operations Analyst — Reporting & Dashboard Development
**ClearTax India** | Oct 2017 – Nov 2020 | Bengaluru

- Built **management and operational dashboards** for real-time productivity and performance
  monitoring across support, sales, marketing, and retention teams.
- Produced **daily, monthly, and quarterly reports** covering sales funnels, marketing
  conversion, revenue performance, and lead utilization metrics.
- Delivered **KPI-driven insights** to business stakeholders that improved team efficiency and
  reduced cost of service.
- Collaborated on **SOPs for the contact center**, standardizing processes across multiple
  operational teams.

---

### Technical Support Engineer
**HP** | Aug 2016 – Aug 2017 | Bengaluru

- Provided L0/L1 technical support for HP products across APJ India region (B2C and B2B).
- Awarded **Best Performer of the Month** for excellence in service quality.

---

## EDUCATION

**Bachelor of Science — Computer Systems Networking & Telecommunications**
Sikkim Manipal University — Distance Education | 2012 – 2015 | Grade: A

---

## PORTFOLIO & PROJECTS

**Real-Time Sales & Weather Analytics Platform** *(In Progress)*
Stack: Snowflake · Snowpark Python · Dynamic Tables · Streamlit · GitHub Actions CI/CD · dbt
- End-to-end pipeline ingesting weather and sales data, transforming via dbt models,
  surfacing insights via Streamlit dashboard with automated CI/CD deployment.
- GitHub: github.com/[YOUR-GITHUB-USERNAME]/[REPO-NAME]

---

## LANGUAGES

English (Professional) | Assamese (Native) | Hindi (Fluent)

---

<!--
=============================================================================
TAILORING GUIDE — Read before customizing for a specific job application
=============================================================================

STEP 1 — Adjust the PROFESSIONAL SUMMARY:
  - Mirror the job title from the posting (e.g., "Data Engineer" vs "Analytics Engineer")
  - Add 1-2 keywords from the JD to the first line
  - Mention specific tools listed in the JD (e.g., dbt, Airflow, Spark, BigQuery)

STEP 2 — Reorder or emphasize TECHNICAL SKILLS:
  - Move the most relevant tool category to the top of the skills table
  - Add any tools from the JD that you have experience with

STEP 3 — Prioritize EXPERIENCE bullets:
  - For Data Engineer roles: lead with pipeline, ETL, SQL, Snowflake bullets
  - For Data Analyst roles: lead with dashboard, KPI, trend analysis, SQL bullets
  - For Analytics Engineer roles: lead with data modeling, dbt, SQL, pipeline bullets

STEP 4 — Add KEYWORDS from the JD naturally into bullet points:
  - ATS systems score based on keyword frequency — match the JD's exact phrasing
  - E.g., if JD says "data pipeline orchestration", add it to a bullet

STEP 5 — Update PORTFOLIO section:
  - Add GitHub URL once repo is live
  - If applying for a specific domain, add a project relevant to that domain

=============================================================================
-->
